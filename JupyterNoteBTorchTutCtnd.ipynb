{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 2119650,
          "sourceType": "datasetVersion",
          "datasetId": 1271856
        }
      ],
      "dockerImageVersionId": 30747,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "JupyterNoteBTorchTutCtnd",
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'miniplaces:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F1271856%2F2119650%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240802%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240802T214313Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D4bfbace518c7a9c5d18389afff5737e05b8a15107d37afb9640af2dea70024f7dda8e53ff8099dece1b0532677a6e2a8eeda5c7f2d6090500a5d3e2a74b7dc846b03b15aadb137b8a832794b197dcceefc3bcadb1765c05321d0f00e9c3e7d1f231bd29fa731197e28007146c5b92fcdf1d572bd1b37cf2c99c9d8f174cac3268d97cac492d5b699f3797f0e1b4b8e310dfcef00e0930bc07b21d28798675c1576a447527e963bb8402e890e281612d8402782db9922cb9b9d66b02d06af62b9288c1c0cda0e393540598f1241124be013015db0aa1f3d52da5c22ffc6e6e7016cc0290ac462b2c9c7b23d50fd1345b7e64ff8e1be908b20b9223191bb8447d9'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "eLsqh6FkDAaL"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2024-07-19T13:36:58.36607Z",
          "iopub.execute_input": "2024-07-19T13:36:58.366478Z",
          "iopub.status.idle": "2024-07-19T13:37:01.912979Z",
          "shell.execute_reply.started": "2024-07-19T13:36:58.366447Z",
          "shell.execute_reply": "2024-07-19T13:37:01.911823Z"
        },
        "trusted": true,
        "id": "wMMY8LlWDAaR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from collections import OrderedDict\n",
        "from torch.nn import Linear, ReLU, Sequential\n",
        "\n",
        "mlp = torch.nn.Sequential(OrderedDict([\n",
        "    ('layer1', Sequential(Linear(2, 20), ReLU())),\n",
        "    ('layer2', Sequential(Linear(20, 20), ReLU())),\n",
        "    ('layer3', Sequential(Linear(20, 2)))\n",
        "]))\n",
        "\n",
        "print(mlp)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-19T13:37:01.914709Z",
          "iopub.execute_input": "2024-07-19T13:37:01.915043Z",
          "iopub.status.idle": "2024-07-19T13:37:01.922942Z",
          "shell.execute_reply.started": "2024-07-19T13:37:01.915013Z",
          "shell.execute_reply": "2024-07-19T13:37:01.921866Z"
        },
        "trusted": true,
        "id": "GJ5tbSbiDAaS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-19T13:37:01.924255Z",
          "iopub.execute_input": "2024-07-19T13:37:01.92456Z",
          "iopub.status.idle": "2024-07-19T13:37:01.9337Z",
          "shell.execute_reply.started": "2024-07-19T13:37:01.924534Z",
          "shell.execute_reply": "2024-07-19T13:37:01.9327Z"
        },
        "trusted": true,
        "id": "6VP9a1ZzDAaT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "def visualize_net(net, classify_target):\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
        "    grid = torch.stack([\n",
        "        torch.linspace(-2, 2, 100)[None, :].expand(100, 100),\n",
        "        torch.linspace(2, -2, 100)[:, None].expand(100, 100),\n",
        "    ])\n",
        "    x, y = grid\n",
        "    target = classify_target(x, y)\n",
        "    ax1.set_title('target')\n",
        "    ax1.imshow(target.float(), cmap='hot', extent=[-2,2,-2,2])\n",
        "    ax2.set_title('network output')\n",
        "    score = net(grid.permute(1, 2, 0).reshape(-1, 2).cuda()).softmax(1)\n",
        "    ax2.imshow(score[:,1].reshape(100, 100).detach().cpu(), cmap='hot', extent=[-2,2,-2,2])\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-19T13:37:01.935766Z",
          "iopub.execute_input": "2024-07-19T13:37:01.936098Z",
          "iopub.status.idle": "2024-07-19T13:37:01.948622Z",
          "shell.execute_reply.started": "2024-07-19T13:37:01.936075Z",
          "shell.execute_reply": "2024-07-19T13:37:01.947775Z"
        },
        "trusted": true,
        "id": "7cHyAfQQDAaU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.functional import cross_entropy\n",
        "from torch.optim import Adam\n",
        "\n",
        "def classify_target(x, y):\n",
        "  return (y.floor() == x.floor()).long()\n",
        "\n",
        "mlp.cuda()\n",
        "optimizer = Adam(mlp.parameters(), lr=.01)\n",
        "for iteration in range(1024):\n",
        "  in_batch = torch.randn(10000, 2, device='cuda')\n",
        "  target_batch = classify_target(in_batch[:,0], in_batch[:,1])\n",
        "  out_batch = mlp(in_batch)\n",
        "  loss = cross_entropy(out_batch, target_batch)\n",
        "  if iteration > 0:\n",
        "    mlp.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  if iteration == 2 ** iteration.bit_length() - 1:\n",
        "    pred_batch = out_batch.max(1)[1]\n",
        "    accuracy = (pred_batch == target_batch).float().sum().item() / len(in_batch)\n",
        "    print(f'iteration {iteration} accuracy {accuracy}')\n",
        "    visualize_net(mlp, classify_target)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-19T13:37:01.94991Z",
          "iopub.execute_input": "2024-07-19T13:37:01.95068Z",
          "iopub.status.idle": "2024-07-19T13:37:07.988244Z",
          "shell.execute_reply.started": "2024-07-19T13:37:01.950644Z",
          "shell.execute_reply": "2024-07-19T13:37:07.987306Z"
        },
        "trusted": true,
        "id": "V6JCCwhRDAaU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### A network can be saved by saving its `state_dict` since it gathers together all the params of the submodule it can save it all at once.\n",
        "\n",
        "### If we wanted to load just a subset of layers, we could do that by picking out keys of the dictionary and adjusting their names by hand."
      ],
      "metadata": {
        "id": "lAwLixE6DAaV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for k, v, in mlp.state_dict().items():\n",
        "    print(f'{k}: {v.dtype}{tuple(v.shape)}')\n",
        "\n",
        "torch.save(mlp.state_dict(), 'checkpoints/mlp.pth')\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-19T13:37:07.98957Z",
          "iopub.execute_input": "2024-07-19T13:37:07.989901Z",
          "iopub.status.idle": "2024-07-19T13:37:08.055894Z",
          "shell.execute_reply.started": "2024-07-19T13:37:07.989875Z",
          "shell.execute_reply": "2024-07-19T13:37:08.053407Z"
        },
        "trusted": true,
        "id": "E_Mkj29CDAaY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Defining `forward` to create custom NeuralNets ðŸ¤“"
      ],
      "metadata": {
        "id": "J3-wiq2bDAaZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Sometimes you will want to hookup network components in a more complicated way than just sequential operationof predefined components\n",
        "\n",
        "#### For eg in ResNets we learn perturbations (where we compare a known solution w/ an unknown\n",
        "#### one and try to solve this way) of the identity. Have a layer learn to compute small residual instead of the whole total answer.\n",
        "\n",
        "![image.png](attachment:416bc8f0-109b-4c71-8838-31fd1c9a05b6.png)![image.png](attachment:6b8b0a7b-5c50-407a-911a-3bbd0d657bd0.png)"
      ],
      "metadata": {
        "id": "sQyN0PUkDAaa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### To apply the residual trick to our 3 layer network, wel define the operation by writing\n",
        "##### our own `forward` function to look like this -"
      ],
      "metadata": {
        "id": "EjG8go60DAaa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class myneuralnet(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.layer1 = Sequential(Linear(2, 20), ReLU())\n",
        "        self.residual_layer2 = Sequential(Linear(20, 20), ReLU())\n",
        "        self.layer3 = Linear(20, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layer1(x)\n",
        "        x = x + self.residual_layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        return x\n",
        "\n",
        "res_mlp = myneuralnet()\n",
        "print(res_mlp)\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-19T13:46:14.893846Z",
          "iopub.execute_input": "2024-07-19T13:46:14.894235Z",
          "iopub.status.idle": "2024-07-19T13:46:15.237778Z",
          "shell.execute_reply.started": "2024-07-19T13:46:14.894203Z",
          "shell.execute_reply": "2024-07-19T13:46:15.236446Z"
        },
        "trusted": true,
        "id": "js8x-R74DAaa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.functional import cross_entropy\n",
        "from torch.optim import Adam\n",
        "\n",
        "def classify_target(x, y):\n",
        "  return (y.floor() == x.floor()).long() ### grid img\n",
        "\n",
        "res_mlp.cuda()\n",
        "optimizer = Adam(res_mlp.parameters(), lr=.01)\n",
        "for iteration in range(1024):\n",
        "  in_batch = torch.randn(10000, 2, device='cuda')\n",
        "  target_batch = classify_target(in_batch[:,0], in_batch[:,1])\n",
        "  out_batch = res_mlp(in_batch)\n",
        "  loss = cross_entropy(out_batch, target_batch)\n",
        "  if iteration > 0:\n",
        "    res_mlp.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  if iteration == 2 ** iteration.bit_length() - 1:\n",
        "    pred_batch = out_batch.max(1)[1]\n",
        "    accuracy = (pred_batch == target_batch).float().sum().item() / len(in_batch)\n",
        "    print(f'iteration {iteration} accuracy {accuracy}')\n",
        "    visualize_net(res_mlp, classify_target)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-19T13:46:15.238588Z",
          "iopub.status.idle": "2024-07-19T13:46:15.238918Z",
          "shell.execute_reply.started": "2024-07-19T13:46:15.238761Z",
          "shell.execute_reply": "2024-07-19T13:46:15.238775Z"
        },
        "trusted": true,
        "id": "R1lx-GYIDAab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Different loss functions in Pytorch ðŸ˜Š"
      ],
      "metadata": {
        "id": "eFrrb8fbDAac"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "input = torch.randn(3, 5, requires_grad=True)\n",
        "target = torch.randn(3, 5)\n",
        "\n",
        "mae_loss = nn.L1Loss()\n",
        "output = mae_loss(input, target)\n",
        "output.backward()\n",
        "\n",
        "print('input: ', input)\n",
        "print('target: ', target)\n",
        "print('output: ', output)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-19T13:46:15.393324Z",
          "iopub.execute_input": "2024-07-19T13:46:15.393622Z",
          "iopub.status.idle": "2024-07-19T13:46:18.749475Z",
          "shell.execute_reply.started": "2024-07-19T13:46:15.393598Z",
          "shell.execute_reply": "2024-07-19T13:46:18.748512Z"
        },
        "trusted": true,
        "id": "KZtFZMxIDAac"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.nn.MSELoss"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-19T13:46:18.751207Z",
          "iopub.execute_input": "2024-07-19T13:46:18.751601Z",
          "iopub.status.idle": "2024-07-19T13:46:18.758152Z",
          "shell.execute_reply.started": "2024-07-19T13:46:18.751576Z",
          "shell.execute_reply": "2024-07-19T13:46:18.757338Z"
        },
        "trusted": true,
        "id": "kIbJQ3RxDAad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.nn.NLLLoss"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-19T13:46:18.759518Z",
          "iopub.execute_input": "2024-07-19T13:46:18.75986Z",
          "iopub.status.idle": "2024-07-19T13:46:18.767541Z",
          "shell.execute_reply.started": "2024-07-19T13:46:18.75983Z",
          "shell.execute_reply": "2024-07-19T13:46:18.766692Z"
        },
        "trusted": true,
        "id": "cKFNjyClDAad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.nn.CrossEntropyLoss"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-19T13:46:18.769754Z",
          "iopub.execute_input": "2024-07-19T13:46:18.770097Z",
          "iopub.status.idle": "2024-07-19T13:46:18.777223Z",
          "shell.execute_reply.started": "2024-07-19T13:46:18.77006Z",
          "shell.execute_reply": "2024-07-19T13:46:18.776437Z"
        },
        "trusted": true,
        "id": "RAVlTgLxDAad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.nn.HingeEmbeddingLoss\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-19T13:46:18.778148Z",
          "iopub.execute_input": "2024-07-19T13:46:18.778406Z",
          "iopub.status.idle": "2024-07-19T13:46:18.786446Z",
          "shell.execute_reply.started": "2024-07-19T13:46:18.778373Z",
          "shell.execute_reply": "2024-07-19T13:46:18.785649Z"
        },
        "trusted": true,
        "id": "y0nXrdZUDAad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.nn.MarginRankingLoss"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-19T13:46:18.788285Z",
          "iopub.execute_input": "2024-07-19T13:46:18.788997Z",
          "iopub.status.idle": "2024-07-19T13:46:18.79626Z",
          "shell.execute_reply.started": "2024-07-19T13:46:18.788953Z",
          "shell.execute_reply": "2024-07-19T13:46:18.795433Z"
        },
        "trusted": true,
        "id": "Hu-UBg3xDAad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.nn.TripletMarginLoss"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-19T13:46:18.797221Z",
          "iopub.execute_input": "2024-07-19T13:46:18.797486Z",
          "iopub.status.idle": "2024-07-19T13:46:18.804916Z",
          "shell.execute_reply.started": "2024-07-19T13:46:18.797459Z",
          "shell.execute_reply": "2024-07-19T13:46:18.804038Z"
        },
        "trusted": true,
        "id": "gLiDrlJLDAad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.nn.KLDivLoss"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-19T13:46:18.806097Z",
          "iopub.execute_input": "2024-07-19T13:46:18.806395Z",
          "iopub.status.idle": "2024-07-19T13:46:18.813361Z",
          "shell.execute_reply.started": "2024-07-19T13:46:18.806373Z",
          "shell.execute_reply": "2024-07-19T13:46:18.812575Z"
        },
        "trusted": true,
        "id": "qj5wrAklDAae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### More on the different loss functions here: https://neptune.ai/blog/pytorch-loss-functions"
      ],
      "metadata": {
        "id": "yk0Br-NoDAae"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ls datasets/miniplaces/val/golf_course"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-19T13:46:18.814462Z",
          "iopub.execute_input": "2024-07-19T13:46:18.814737Z",
          "iopub.status.idle": "2024-07-19T13:46:19.865024Z",
          "shell.execute_reply.started": "2024-07-19T13:46:18.814715Z",
          "shell.execute_reply": "2024-07-19T13:46:19.863982Z"
        },
        "trusted": true,
        "id": "eAcqdp0bDAae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Constructing an Imagefolder in Pytorch ðŸŒ‡ðŸŒ†"
      ],
      "metadata": {
        "id": "Me4BoM1aDAae"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision.transforms import ToPILImage\n",
        "import os\n",
        "\n",
        "### Define the path to the dataset (kaggle dataset path)\n",
        "\n",
        "dataset_path = '/kaggle/input/miniplaces/data/val'\n",
        "\n",
        "### Define transformation operations for more clarity\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "### Load the dataset using ImageFolder\n",
        "val_set = datasets.ImageFolder(root=dataset_path, transform=transform)\n",
        "print('Length is', len(val_set))\n",
        "\n",
        "\n",
        "## Get the 51000th item from the dataset\n",
        "item = val_set[5100]\n",
        "print('5100th item is a pair', item)\n",
        "\n",
        "### Display the class name of the 5100th item\n",
        "print('Class name is', val_set.classes[item[1]])\n",
        "\n",
        "## Display the image\n",
        "\n",
        "to_pil = ToPILImage()\n",
        "image = to_pil(item[0])\n",
        "\n",
        "# Display the image\n",
        "image = transforms.ToPILImage()(item[0])\n",
        "plt.imshow(image)\n",
        "plt.title(val_set.classes[item[1]])\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-19T13:46:19.868384Z",
          "iopub.execute_input": "2024-07-19T13:46:19.868725Z",
          "iopub.status.idle": "2024-07-19T13:46:23.285109Z",
          "shell.execute_reply.started": "2024-07-19T13:46:19.868699Z",
          "shell.execute_reply": "2024-07-19T13:46:23.284181Z"
        },
        "trusted": true,
        "id": "R94U3aKODAae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transforming a PIL image into a pytorch tensor ðŸŒ‡ðŸ”¥"
      ],
      "metadata": {
        "id": "1_w44pmDDAaf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### A pil image is not convenient for training - we would prefer our data to return to torch tensor.\n",
        "### So we tell `ImageFolder` to do this by specifying transform function on construction.\n",
        "### Pytorch comes with a standard transform function also `torchvision.transforms.ToTensor()`"
      ],
      "metadata": {
        "id": "PRcKP_QuDAaf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "print('Going over the dataset as an array')\n",
        "start = time.time()\n",
        "summed_image_dataset = 0\n",
        "batch_size = 100\n",
        "for i in range(0, len(val_set), batch_size):\n",
        "    image_batch = torch.stack([val_set[i+j][0] for j in range(batch_size)])\n",
        "    summed_image_dataset += image_batch.sum(0)\n",
        "end = time.time()\n",
        "print(f'Took {end - start} seconds')\n",
        "\n",
        "### using torch.utils\n",
        "\n",
        "print('Going over the same dataset using a dataloader')\n",
        "\n",
        "start = time.time()\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "    val_set, batch_size=batch_size, num_workers=10)\n",
        "summed_image_loader = 0\n",
        "for image_batch, label_batch in val_loader:\n",
        "    summed_image_loader += image_batch.sum(0)\n",
        "end = time.time()\n",
        "print(f'Took {end - start} seconds')\n",
        "\n",
        "print('Numerical difference is exactly', (summed_image_loader - summed_image_dataset).norm().item())\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-19T13:46:23.286381Z",
          "iopub.execute_input": "2024-07-19T13:46:23.286791Z",
          "iopub.status.idle": "2024-07-19T13:46:55.645759Z",
          "shell.execute_reply.started": "2024-07-19T13:46:23.286764Z",
          "shell.execute_reply": "2024-07-19T13:46:55.644671Z"
        },
        "trusted": true,
        "id": "_1fq0PaWDAaf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### yea so its substantialy better to use `torch.utils()` ðŸ˜…"
      ],
      "metadata": {
        "id": "9L6H4asJDAag"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Exercise\n",
        "\n",
        "## Try and alter -\n",
        "\n",
        "# 1. num_workers and note the changes in speed\n",
        "# 2. batch_size and note the changes in speed.\n",
        "\n",
        "\n",
        "import time\n",
        "\n",
        "print('Going over the dataset as an array')\n",
        "start = time.time()\n",
        "summed_image_dataset = 0\n",
        "batch_size = 100\n",
        "for i in range(0, len(val_set), batch_size):\n",
        "    image_batch = torch.stack([val_set[i+j][0] for j in range(batch_size)])\n",
        "    summed_image_dataset += image_batch.sum(0)\n",
        "end = time.time()\n",
        "print(f'Took {end - start} seconds')\n",
        "\n",
        "### using torch.utils\n",
        "\n",
        "print('Going over the same dataset using a dataloader')\n",
        "\n",
        "start = time.time()\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "    val_set, batch_size=batch_size, num_workers=10)\n",
        "summed_image_loader = 0\n",
        "for image_batch, label_batch in val_loader:\n",
        "    summed_image_loader += image_batch.sum(0)\n",
        "end = time.time()\n",
        "print(f'Took {end - start} seconds')\n",
        "\n",
        "print('Numerical difference is exactly', (summed_image_loader - summed_image_dataset).norm().item())\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-19T13:46:55.647333Z",
          "iopub.execute_input": "2024-07-19T13:46:55.647778Z",
          "iopub.status.idle": "2024-07-19T13:47:09.172361Z",
          "shell.execute_reply.started": "2024-07-19T13:46:55.647723Z",
          "shell.execute_reply": "2024-07-19T13:47:09.171265Z"
        },
        "trusted": true,
        "id": "XBMt8w-TDAag"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Other common dataloader tricks. `DataLoader` can do a few more useful things.\n",
        "\n",
        "-  Although a `DataLoader` does not put batches on the GPU directly (because of multithreading limitations), it can put the batch in pinned memory, which is faster to copy to the GPU later after you get it out of the DataLoader. Make the DataLoader with `pin_memory=True` for this.\n",
        "\n",
        "- During training you usually do not want the batches in alphabetical order. The DataLoader can shuffle the batches so that they are randomized, instead of sequential. `shuffle=True` for this."
      ],
      "metadata": {
        "id": "a1Fn6vznDAah"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Now wel train a classifier, using adam optim and a simplified version of Res-Net 18 neuralnet ðŸ”¥"
      ],
      "metadata": {
        "id": "nME-CxhBDAah"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "from torchvision import datasets, transforms, models\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision.transforms import ToPILImage\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "## Create a dataset of miniplaces training images\n",
        "\n",
        "### Define the path to the dataset (kaggle dataset path)\n",
        "\n",
        "dataset_path = '/kaggle/input/miniplaces/data/val'\n",
        "\n",
        "### Define transformation operations for more clarity\n",
        "\n",
        "### instead of `.Compose()` this could also simply be `.torchvision`\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "### Load the dataset using ImageFolder\n",
        "train_set = datasets.ImageFolder(root=dataset_path, transform=transform)\n",
        "print('Length is', len(train_set))\n",
        "\n",
        "### Wrapping the dataset in a high-speed DataLoader w batch_size 100\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_set, batch_size=100, num_workers=10,\n",
        "    shuffle=True,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "### Creating an untrained neuralnet using the ResNet 18 architecture\n",
        "\n",
        "model = torchvision.models.resnet18(num_classes=100).cuda()\n",
        "\n",
        "\n",
        "### Set up the model for training using the Adam Optim\n",
        "model.train()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "### Now training, optimizing an objective on batches\n",
        "### Here we look at the image once\n",
        "\n",
        "for batch in tqdm(train_loader):\n",
        "    images, labels = [d.cuda() for d in batch]\n",
        "    optimizer.zero_grad()\n",
        "    scores = model(images.cuda())\n",
        "    loss = torch.nn.functional.cross_entropy(scores, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-19T14:49:03.449131Z",
          "iopub.execute_input": "2024-07-19T14:49:03.449495Z",
          "iopub.status.idle": "2024-07-19T14:49:15.154744Z",
          "shell.execute_reply.started": "2024-07-19T14:49:03.449466Z",
          "shell.execute_reply": "2024-07-19T14:49:15.153602Z"
        },
        "trusted": true,
        "id": "10cP5zSQDAah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Checking accuracy w a heldout Dataset ðŸ¤“\n",
        "\n",
        "### Now we can do this easily by greating a second `ImageFolder` dataset and `DataLoader` with a second set\n",
        "### of images not used for training."
      ],
      "metadata": {
        "id": "Dmw-O9CaDAah"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms, models\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision.transforms import ToPILImage\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "## Create a dataset of miniplaces training images\n",
        "\n",
        "### Define the path to the dataset (kaggle dataset path)\n",
        "\n",
        "dataset_path = '/kaggle/input/miniplaces/data/val'\n",
        "\n",
        "### Define transformation operations for more clarity\n",
        "\n",
        "### instead of `.Compose()` this could also simply be `.torchvision`\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "### Load the dataset using ImageFolder\n",
        "val_set = datasets.ImageFolder(root=dataset_path, transform=transform)\n",
        "print('Length is', len(train_set))\n",
        "\n",
        "### Wrapping the dataset in a high-speed DataLoader w batch_size 100\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "    val_set, batch_size=100, num_workers=10,\n",
        "    shuffle=True,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "### Now this function runs over validation images and counts accurate preds :>\n",
        "\n",
        "def accuracy():\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    for iter, batch in enumerate(val_loader):\n",
        "        images, labels = [d.cuda() for d in batch]\n",
        "        with torch.no_grad():\n",
        "            scores = model(images.cuda())\n",
        "        correct += (scores.max(1)[1] == labels).float().sum()\n",
        "    return correct.item() / len(val_set)\n",
        "\n",
        "print(f'Accuracy on unseen images {accuracy() * 100}% (random guesses would be 1%)')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-19T14:59:54.767495Z",
          "iopub.execute_input": "2024-07-19T14:59:54.76849Z",
          "iopub.status.idle": "2024-07-19T14:59:59.583361Z",
          "shell.execute_reply.started": "2024-07-19T14:59:54.768441Z",
          "shell.execute_reply": "2024-07-19T14:59:59.581548Z"
        },
        "trusted": true,
        "id": "bQh4mEPJDAai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Improving our model with Data Augmentation ðŸ˜…"
      ],
      "metadata": {
        "id": "DI-8kQNDDAai"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### For example if we randomly adjust the crop, color, or orientation of the image while loading, using the same image file multiple times will produce different training examples for the network.\n",
        "\n",
        "### This is an easy way to increase the amount of training diversity in the data set without requring more actual images.\n",
        "\n",
        "### To do data augmentation in a pytorch Dataset, you can specify more operations on `transform=` besides `ToTensor()`"
      ],
      "metadata": {
        "id": "UhBWi2xNDAai"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Using Data Augmentation to try to improve our model :>\n",
        "\n",
        "import torch\n",
        "from torchvision import datasets, transforms, models\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision.transforms import ToPILImage\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "## Create a dataset of miniplaces training images\n",
        "\n",
        "### Define the path to the dataset (kaggle dataset path)\n",
        "\n",
        "dataset_path = '/kaggle/input/miniplaces/data/val'\n",
        "\n",
        "### Define transformation operations for more clarity\n",
        "\n",
        "### instead of `.Compose()` this could also simply be `.torchvision`\n",
        "transform = transforms.Compose([\n",
        "    transforms.RandomCrop(112),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "### Load the dataset using ImageFolder\n",
        "train_set = datasets.ImageFolder(root=dataset_path, transform=transform)\n",
        "print('Length is', len(train_set))\n",
        "\n",
        "### Wrapping the dataset in a high-speed DataLoader w batch_size 100\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_set, batch_size=100, num_workers=10,\n",
        "    shuffle=True,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "### Creating an untrained neuralnet using the ResNet 18 architecture\n",
        "\n",
        "#model = torchvision.models.resnet18(num_classes=100).cuda()\n",
        "\n",
        "### Set up the model for training using the Adam Optim\n",
        "model.train()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "### Now training, optimizing an objective on batches\n",
        "### Here we look at the image once\n",
        "\n",
        "for batch in tqdm(train_loader):\n",
        "    images, labels = [d.cuda() for d in batch]\n",
        "    optimizer.zero_grad()\n",
        "    scores = model(images.cuda())\n",
        "    loss = torch.nn.functional.cross_entropy(scores, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "print(f'Accuracy on unseen images {accuracy() * 100}% (random guesses would be 1%)')\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-19T15:17:04.965921Z",
          "iopub.execute_input": "2024-07-19T15:17:04.966755Z",
          "iopub.status.idle": "2024-07-19T15:17:18.407821Z",
          "shell.execute_reply.started": "2024-07-19T15:17:04.966711Z",
          "shell.execute_reply": "2024-07-19T15:17:18.406588Z"
        },
        "trusted": true,
        "id": "m_79BXHIDAai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VmEIYg7ODAan"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "z1g2iuDeDAan"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1pIfObM3DAan"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8SSZmFl5DAan"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YM5br9rfDAan"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KdzPVPl9DAan"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jImqGAIPDAao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "13MyIfFeDAao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "crq7hs6dDAao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U5xFtYUKDAao"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}